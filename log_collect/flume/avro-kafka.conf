#第二层agent，部署到mini2和mini3

# /opt/apps/flume/bin/flume-ng agent -n a1 -c /opt/apps/flume/conf -f /opt/apps/flume/config/avro-kafka.conf -Dflume.root.logger=INFO,console
# nohup /opt/apps/flume/bin/flume-ng agent -n a1 -c /opt/apps/flume/conf -f /opt/apps/flume/config/avro-kafka.conf 1>/dev/null 2>/dev/null &

a1.sources = r1
a1.channels = c1
a1.sinks = k1

#source
a1.sources.r1.type = avro
a1.sources.r1.channels = c1
#这个需要修改(192.168.80.92,   192.168.70.92,    192.168.60.92,      192.168.50.92)
a1.sources.r1.bind = 192.168.80.92
a1.sources.r1.port = 9999

#channel
a1.channels.c1.type = file
#这个需要修改
a1.channels.c1.checkpointDir = /opt/apps/flume/checkpoint/channel
#这个需要修改
a1.channels.c1.dataDirs = /opt/apps/flume/data
a1.channels.c1.maxFileSize = 104857600
a1.channels.c1.capacity = 90000000
a1.channels.c1.keep-alive = 60


#sink
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.topic = event_log
#这个需要修改（kafka节点地址）
a1.sinks.k1.brokerList = mini1:9092,mini2:9092,mini3:9092

#保证消息完整生成
# 设置发送数据是否需要服务端的反馈,有四个值0,1,-1 all
# 0: producer不会等待broker发送ack
# 1: 当leader接收到消息之后发送ack
# -1: 当所有的follower都同步消息成功后发送ack.
a1.sinks.k1.requiredAcks = 1
a1.sinks.k1.kafka.producer.type = sync
a1.sinks.k1.batchSize = 1
a1.sinks.k1.channel = c1

#a1.sinks.k1.type = logger
#a1.sinks.k1.channel = c1
